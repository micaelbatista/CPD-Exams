# Exame 2 - 15/16

## Grupo I

### 1.a

A variavel sum esta a ser partilhada por todos, o que pode causar exclusoes mutuas entre as threads.



### 1.b

```c
#pragma omp parallel for reduction(+:sum)
```



### 2.a

A versao 2 porque so precisa de iniciar as threads 1 vez, ao contrario da versao 1, que em cada iteracao do i, iniciaria as threads.



### 2.b

Essa tag define para se fazer um scheduling das threads usando uma divisao estatica com blocos de 20. Ou seja, o nº de iteracoes seria dividido pelas threads em conjuntos de 20 iterações. Os blocos seriam distribuidos numa maneira round-robin (dava a T1, T2, T3 e dps voltava a T1).

Se o chuck size se mantiver 20, mas $ M \lt 20 $ então poderia haver threads sem terem trabalho p fazer, ja que existe uma barreira implicita no final do for.





## Grupo II

### 1.a

O broadcast de um array de elementos é basicamente enviar o array para os varios processadores. 

A implementacao sugerida iria ter o mesmo resultado. o _MPI_Scatter_ faria com que fosse enviado uma parte do array para cada processador. Com o *MPI_Allgather* a seguir, todos os processadores enviariam a sua parte do array para os outros processadores e recebessem dos outros processadores o resto do array.



### 1.b

$ Sending\_message(message\_size) = \lambda + \frac{message\_size}{\beta}  $

$ Broadcast\_time = log(p) \cdot Sending\_message(n) = log(p) \cdot (\lambda + \frac{n}{\beta})$

$ Scatter\_Allgather\_time = 2 (p-1) \cdot Sending\_message(\frac{n}{p}) = 2(p-1)(\lambda + \frac{n}{p \beta}) $

**???**: No idea what I'm doing



### 2

```c
double sum = 0;
double final_sum = 0;
int i;
double* my_array;
MPI_Scatter(&very_large_array, VERY_LARGE_ARRAY_SIZE, MPI_DOUBLE, my_array, VERY_LARGE_ARRAY_SIZE/PROC_COUNT, MPI_DOUBLE, 0, MPI_COMM_WORLD);

for(i = 0; i < VERY_LARGE_ARRAY_SIZE/PROC_COUNT; i++)
	sum += my_array[i];

MPI_Reduce(&sum, &final_sum, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);

if(my_mpi_rank == 0)
	return final_sum/VERY_LARGE_ARRAY_SIZE;
else
  	return -1.0;
```





## Grupo III

### 1.a

A funcao de escalabilidade indica a memoria necessaria tendo em conta os requisitos de memoria e a isoeficiencia. Ter uma funcao de escalabilidade $ p^3 $ significa que a memoria necessaria aumenta com os nº de processadores ao cubo, o que é uma pessima escalabilidade



### 1.b

$ M(n) = n^2 $

$ Escalabilidade: p^3 = \frac{M(n)}{p} = \frac{n^2}{p} \Leftrightarrow n = p $

$ Isoeficiencia: n \geq p $



A isoeficiencia diz que para manter uma resolucao eficiente de um certo problema, este problema tem de acompanhar o crescimento dos processadores.



### 2

Porque e necessario fazer testes ao speedup de forma a se conseguir obter a fração sequencial de um determinado programa.



### 3.a

10



### 3.b

$ \frac{0.1}{0.9/9+0.1} = 50\% $





## Grupo IV

### 1 

Sim. No entanto, ha um aumento na dificuldade de desenvolvimento, ja que o programador tem de estar mais atento relativamente a gestao de memoria. Para alem disso, pode haver uma degradacao na performance.



### 2

Permite guardar informacao redudante que esta a ser utilizada por um processo vizinho.

isto evita que haja exclusao mutua entre processos, o que faz com que haja uma melhoria em velocidade.

Em contrapartida, tem de se consumir mais memoria.



### 3.a

Algoritmos que funcionam em pipeline



### 3.b

branco quer dizer que todos os nos ate um determinado ponto ja acabaram as tarefas que tinham para fazer. caso contrario, e preto.

