# Exame 1 - 14/15

## Grupo I

### 1

```c
#pragma omp parallel for private(i,j)
for(i = 0; i < N; i++) {
	M = random1000();
  	for(j = 0; j < M; j++)
    	a[i][j] *= 2.0 + a[i][j];
}
```

???: Talvez usar dynamic scheduling em vez de static por causa do random (pode haver tarefas mais simples que outras)



### 2

Em OpenMP, deve-se usar chunks pequenos quando não é possivel prever a quantidade de trabalho que uma determinada tarefa ira ter. Contudo, se for possivel fazer uma previsao aproximada do trabalho necessario fazer para uma tarefa, e preferivel usar chunks maiores. Isto permite que haja um menor overhead por se ter de ir buscar as tarefas a uma queue.



### 3

Num sistema que use UMA, existe uma memória principal a que todos acedem. Os nós normalmente também têm uma cache de forma a reduzir o número de acessos à memória principal (quando se escreve algo em memória usa-se a politica write-back). De forma a garantir coerência na memória, pode-se usar coerência baseada em diretórios (o estado de cada bloco é mantido num diretório) ou snooping (o bus principal é monitorizado de forma a saber-se se os blocos que se tem em cache foram alterados).

Num sistema que use DSM, a memória está distribuida pelos vários nós. De forma a garantir coerência na memória, usa-se uma tabela de páginas distribuidas que guarda o estado de cada página. No caso de uma determinada página não existir, esta página é criada e fica associada ao nó que a criou.

Tendo em conta as particularidades de cada sistema, numa perpetiva de programador, é mais fácil programar num sistema que use UMA, já que existe apenas uma memória, em oposição de se ter de gerir várias memórias distribuidas pelos nós. No entanto, este modelo é muito menos escalavel que o DSM, que o espaço de memória aumenta com o número de nós. Mesmo que se aumente a memória principal no UMA, o bus partilhado passa a ser uma limitação no sistema, já que todos os processadores irão lá buscar blocos.



## Grupo II

### 1

```c
int MPI_tag = 123;

if(my_MPI_rank == 0) {
  // I'm the master
  MPI_Request slave_request[slave_count];
  int slave_current_index[slave_count];  
  
  for(i = 0; i < slave_count; i++) {
    const int i_to_send = i;
    MPI_Isend(&to_send, 1, MPI_INT, i+1, MPI_tag, MPI_COMM_WORLD, &slave_request[i]);
    slave_current_index[i] = i;
  }
  
  for(i = slave_count; i < N; i++) {
    const int i_to_send = i;
    int slave_id;
    MPI_Status mpi_status;
    TypeOfArrayB result;
    
  	MPI_Waitany(slave_count, slave_request, &slave_id, &mpi_status);    
    MPI_Recv(&result, 1, TypeOfArrayB, slave_id, MPI_tag, MPI_COMM_WORLD, &mpi_status);
    
    b[current_slave_index[slave_id-1]] = result;
    
    MPI_Isend(&i_to_send, 1, MPI_INT, slave_id, MPI_tag, MPI_COMM_WORLD, &slave_request[slave_id-1]);
    
    current_slave_index[slave_id-1] = i;    
  } 
  
  const int to_send = -1;
  MPI_Status all_status[slave_count];
  MPI_Waitall(slave_count, slave_request, all_status);
  
  for(i = 0; i < slave_count; i++)
    MPI_Isend(&to_send, 1, MPI_INT, i+1, MPI_tag, MPI_COMM_WORLD, &slave_request[i]);
  
} else {
    MPI_Status mpi_status;
    MPI_Request mpi_request;
  	TypeOfArrayA input;
  	TypeOfArrayB output;
  
  	while(1) {
      MPI_Recv(&input, 1, TypeOfArrayA, 0, MPI_tag, MPI_COMM_WORLD, &mpi_status);
      if(input < 0) break;
      output = DoComputation(input);
      MPI_Isend(&output, 1, TypeOfArrayB, 0, MPI_tag, MPI_COMM_WORLD, &mpi_request);
  	}
}

MPI_Finalize();
```



### 2.a/b

Serve para identificar o tipo da mensagem (pode ter varios usos como identificar qual e o objetivo da mensagem, o tipo que esta a ser enviado, o tamanho, etc...)



### 2c

É uma maneira simples de validar se a mensagem que estamos a receber é a que queremos receber. 



### 3 

A complexidade é sempre $O(p^2)$, porque no allgather cada processo manda p mensagens e recebe p mensagens

Por exemplo, vamos dizer que temos 3 processos em que cada um tem um nº. No final, todos os processos terão os nºs de todos os processos naquela rede. 

???: O prof no slide 15 diz q a complexidade é $O(log p + n)$, pq???



## Grupo III

### 1





